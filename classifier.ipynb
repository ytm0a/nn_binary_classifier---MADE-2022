{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32ee8c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.008188</td>\n",
       "      <td>0.046069</td>\n",
       "      <td>0.084133</td>\n",
       "      <td>-0.034631</td>\n",
       "      <td>-0.014021</td>\n",
       "      <td>1.537025</td>\n",
       "      <td>0.115259</td>\n",
       "      <td>-0.086073</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>0.241310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097963</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.029191</td>\n",
       "      <td>-0.009160</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>0.064066</td>\n",
       "      <td>-0.205739</td>\n",
       "      <td>-0.122300</td>\n",
       "      <td>0.287233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.057552</td>\n",
       "      <td>6.858400</td>\n",
       "      <td>2.695550</td>\n",
       "      <td>2.765791</td>\n",
       "      <td>7.261945</td>\n",
       "      <td>0.441206</td>\n",
       "      <td>2.762552</td>\n",
       "      <td>2.742284</td>\n",
       "      <td>2.748676</td>\n",
       "      <td>5.454805</td>\n",
       "      <td>...</td>\n",
       "      <td>2.911122</td>\n",
       "      <td>6.131952</td>\n",
       "      <td>7.884183</td>\n",
       "      <td>2.725234</td>\n",
       "      <td>2.752172</td>\n",
       "      <td>5.803769</td>\n",
       "      <td>2.779181</td>\n",
       "      <td>6.522376</td>\n",
       "      <td>6.802771</td>\n",
       "      <td>0.452503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-11.852801</td>\n",
       "      <td>-27.841715</td>\n",
       "      <td>-10.613443</td>\n",
       "      <td>-10.931017</td>\n",
       "      <td>-28.752811</td>\n",
       "      <td>1.000020</td>\n",
       "      <td>-10.311434</td>\n",
       "      <td>-10.075589</td>\n",
       "      <td>-10.141371</td>\n",
       "      <td>-19.277277</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.638970</td>\n",
       "      <td>-28.953492</td>\n",
       "      <td>-33.201209</td>\n",
       "      <td>-11.850828</td>\n",
       "      <td>-9.478779</td>\n",
       "      <td>-20.325866</td>\n",
       "      <td>-9.926252</td>\n",
       "      <td>-28.539398</td>\n",
       "      <td>-28.483072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.062561</td>\n",
       "      <td>-4.317894</td>\n",
       "      <td>-1.740497</td>\n",
       "      <td>-1.896934</td>\n",
       "      <td>-4.743647</td>\n",
       "      <td>1.189318</td>\n",
       "      <td>-1.703177</td>\n",
       "      <td>-1.950722</td>\n",
       "      <td>-1.846900</td>\n",
       "      <td>-3.445588</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.078737</td>\n",
       "      <td>-3.974946</td>\n",
       "      <td>-5.151041</td>\n",
       "      <td>-1.844369</td>\n",
       "      <td>-1.902487</td>\n",
       "      <td>-3.784460</td>\n",
       "      <td>-1.790703</td>\n",
       "      <td>-4.666848</td>\n",
       "      <td>-4.573261</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.017501</td>\n",
       "      <td>-0.053759</td>\n",
       "      <td>0.084710</td>\n",
       "      <td>-0.075840</td>\n",
       "      <td>-0.091840</td>\n",
       "      <td>1.414150</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>-0.063503</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>0.261190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088714</td>\n",
       "      <td>-0.008010</td>\n",
       "      <td>-0.050073</td>\n",
       "      <td>-0.007633</td>\n",
       "      <td>-0.007796</td>\n",
       "      <td>0.166533</td>\n",
       "      <td>0.027659</td>\n",
       "      <td>-0.234126</td>\n",
       "      <td>-0.093245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.991994</td>\n",
       "      <td>4.245097</td>\n",
       "      <td>1.921483</td>\n",
       "      <td>1.777565</td>\n",
       "      <td>4.788682</td>\n",
       "      <td>1.759918</td>\n",
       "      <td>1.964735</td>\n",
       "      <td>1.786275</td>\n",
       "      <td>1.892030</td>\n",
       "      <td>3.906689</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921656</td>\n",
       "      <td>4.007312</td>\n",
       "      <td>5.322672</td>\n",
       "      <td>1.840979</td>\n",
       "      <td>1.833849</td>\n",
       "      <td>4.026855</td>\n",
       "      <td>1.931042</td>\n",
       "      <td>4.296710</td>\n",
       "      <td>4.339118</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.902967</td>\n",
       "      <td>34.619762</td>\n",
       "      <td>9.492417</td>\n",
       "      <td>11.881847</td>\n",
       "      <td>26.337084</td>\n",
       "      <td>2.717640</td>\n",
       "      <td>10.887146</td>\n",
       "      <td>10.071861</td>\n",
       "      <td>10.213687</td>\n",
       "      <td>21.919386</td>\n",
       "      <td>...</td>\n",
       "      <td>11.498217</td>\n",
       "      <td>26.914131</td>\n",
       "      <td>36.333892</td>\n",
       "      <td>9.047867</td>\n",
       "      <td>11.195738</td>\n",
       "      <td>22.448674</td>\n",
       "      <td>9.925644</td>\n",
       "      <td>27.139111</td>\n",
       "      <td>26.071364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  6963.000000  6963.000000  6963.000000  6963.000000  6963.000000   \n",
       "mean     -0.008188     0.046069     0.084133    -0.034631    -0.014021   \n",
       "std       3.057552     6.858400     2.695550     2.765791     7.261945   \n",
       "min     -11.852801   -27.841715   -10.613443   -10.931017   -28.752811   \n",
       "25%      -2.062561    -4.317894    -1.740497    -1.896934    -4.743647   \n",
       "50%      -0.017501    -0.053759     0.084710    -0.075840    -0.091840   \n",
       "75%       1.991994     4.245097     1.921483     1.777565     4.788682   \n",
       "max      12.902967    34.619762     9.492417    11.881847    26.337084   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  6963.000000  6963.000000  6963.000000  6963.000000  6963.000000  ...   \n",
       "mean      1.537025     0.115259    -0.086073     0.029376     0.241310  ...   \n",
       "std       0.441206     2.762552     2.742284     2.748676     5.454805  ...   \n",
       "min       1.000020   -10.311434   -10.075589   -10.141371   -19.277277  ...   \n",
       "25%       1.189318    -1.703177    -1.950722    -1.846900    -3.445588  ...   \n",
       "50%       1.414150     0.143693    -0.063503     0.063927     0.261190  ...   \n",
       "75%       1.759918     1.964735     1.786275     1.892030     3.906689  ...   \n",
       "max       2.717640    10.887146    10.071861    10.213687    21.919386  ...   \n",
       "\n",
       "                22           23           24           25           26  \\\n",
       "count  6963.000000  6963.000000  6963.000000  6963.000000  6963.000000   \n",
       "mean     -0.097963     0.025496     0.029191    -0.009160     0.003571   \n",
       "std       2.911122     6.131952     7.884183     2.725234     2.752172   \n",
       "min     -10.638970   -28.953492   -33.201209   -11.850828    -9.478779   \n",
       "25%      -2.078737    -3.974946    -5.151041    -1.844369    -1.902487   \n",
       "50%      -0.088714    -0.008010    -0.050073    -0.007633    -0.007796   \n",
       "75%       1.921656     4.007312     5.322672     1.840979     1.833849   \n",
       "max      11.498217    26.914131    36.333892     9.047867    11.195738   \n",
       "\n",
       "                27           28           29           30       target  \n",
       "count  6963.000000  6963.000000  6963.000000  6963.000000  6963.000000  \n",
       "mean      0.158798     0.064066    -0.205739    -0.122300     0.287233  \n",
       "std       5.803769     2.779181     6.522376     6.802771     0.452503  \n",
       "min     -20.325866    -9.926252   -28.539398   -28.483072     0.000000  \n",
       "25%      -3.784460    -1.790703    -4.666848    -4.573261     0.000000  \n",
       "50%       0.166533     0.027659    -0.234126    -0.093245     0.000000  \n",
       "75%       4.026855     1.931042     4.296710     4.339118     1.000000  \n",
       "max      22.448674     9.925644    27.139111    26.071364     1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataframe_train = pd.read_csv (\"train.csv\")\n",
    "dataframe_train.describe()\n",
    "#dataframe_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "561c5ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3963, 31), (3963,))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Нужна кросс-валидация\n",
    "x_train = dataframe_train.iloc[0:1000, :31].values.tolist() + dataframe_train.iloc[2000:3000, :31].values.tolist() + dataframe_train.iloc[4000:5000, :31].values.tolist() + dataframe_train.iloc[6000:6963, :31].values.tolist()\n",
    "            \n",
    "y_train = dataframe_train.iloc[0:1000, 31].values.tolist() + dataframe_train.iloc[2000:3000, 31].values.tolist() + dataframe_train.iloc[4000:5000, 31].values.tolist() + dataframe_train.iloc[6000:6963, 31].values.tolist()\n",
    "\n",
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c734fcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 31), (3000,))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_test = dataframe_train.iloc[1000:2000, :31].values.tolist() + dataframe_train.iloc[3000:4000, :31].values.tolist() + dataframe_train.iloc[5000:6000, :31].values.tolist()\n",
    "y_test = dataframe_train.iloc[1000:2000, 31].values.tolist() + dataframe_train.iloc[3000:4000, 31].values.tolist() + dataframe_train.iloc[5000:6000, 31].values.tolist()\n",
    "\n",
    "np.shape(x_test), np.shape(y_test)\n",
    "#/Нужна кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f8f2312a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 31])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(31,))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "151530fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_classifier_med\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 31)]              0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 32)                1024      \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense = layers.Dense(32, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "outputs = layers.Dense(1, activation='tanh')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"binary_classifier_med\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4935af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.9553\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.9611\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9659\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9687\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9727\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9745\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9765\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9783\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9811\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9836\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9854\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9861\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9881\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9891\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9907\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9919\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9907\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9922\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9922\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9929\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9937\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9942\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9947\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9939\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9952\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9950\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9952\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9955\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9955\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9952\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9960\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9960\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9957\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9960\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9960\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9965\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9960\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9950\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9962\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9967\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9962\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9965\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9972\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9967\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9970\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9970\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9970\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9970\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9972\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9970\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9977\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9972\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9980\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9977\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9975\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9975\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9982\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9980\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9982\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9982\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9982\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9985\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9982\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9982\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9982\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9985\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9985\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9982\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9985\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9985\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9985\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9985\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9982\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9985\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9987\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9990\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9990\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9990\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9990\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9990\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9990\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9985\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9990\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9990\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9990\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9990\n",
      "94/94 - 0s - loss: 0.0851 - accuracy: 0.9820 - 257ms/epoch - 3ms/step\n",
      "Test loss: 0.08507509529590607\n",
      "Test accuracy: 0.9819999933242798\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction=\"auto\",\n",
    "    name=\"binary_crossentropy\",\n",
    "),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=100)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8e6e4432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3920, 31)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test_no_validation = pd.read_csv (\"test.csv\")\n",
    "x_pred = dataframe_test_no_validation.values.tolist()\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_pred)\n",
    "Y = (y_pred > .5).astype(int)\n",
    "np.savetxt('pred.csv',Y, fmt='%d',header='target')\n",
    "np.shape(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c94411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
